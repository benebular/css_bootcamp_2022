{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "49880118",
   "metadata": {},
   "source": [
    "# Word Counts in Language Data\n",
    "\n",
    "So, we'll start by importing some things:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6427ec6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "# This allows us to use regex replace later\n",
    "import re\n",
    "import seaborn as sns\n",
    "\n",
    "# Natural Language Toolkit\n",
    "import nltk\n",
    "from nltk import word_tokenize\n",
    "from nltk.util import ngrams\n",
    "from nltk.util import skipgrams\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b49b29d6",
   "metadata": {},
   "source": [
    "Now, let's pull in some text.  In the name of making you practice, **change the code below to read in the file located at the root of your datahub drive at `css_bootcamp_2022/unix/literature/thebrotherskaramazov.txt`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4523c375",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/Users/wstyler/github/css_bootcamp_2022/unix/literature/thebrotherskaramazov.txt') as f:\n",
    "    broskis = f.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "077a9279",
   "metadata": {},
   "source": [
    "First, we'll tokenize the data using `nltk.word_tokenize(yourdata)`. **Figure out why I used .lower() below, then look at the first ten items.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0339f2c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "token = nltk.word_tokenize(broskis.lower())\n",
    "token[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01748b4f",
   "metadata": {},
   "source": [
    "This is gonna be lot of text.  **Figure out how many items are in the list.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "affd19f5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "929792fb",
   "metadata": {},
   "source": [
    "Oh no, that's a LOT of text.  **Save only the first 25000 words, then confirm by counting the number of items that that's what you've done.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "112c06f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e60268d",
   "metadata": {},
   "source": [
    "Now let's split it into a list of bigrams (that is, sets of 2 adjacent words).  **Make the split then look at the first ten items of the list. You'll get this by running `list(ngrams(data,N))`**. The list() element is because the `ngram` command natively creates a type of object called a `zip`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f733c8a3",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ngrams' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [1]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m ng \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[43mngrams\u001b[49m(token,\u001b[38;5;241m2\u001b[39m))\n\u001b[1;32m      2\u001b[0m ng[\u001b[38;5;241m1\u001b[39m:\u001b[38;5;241m10\u001b[39m]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'ngrams' is not defined"
     ]
    }
   ],
   "source": [
    "## Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "debb6877",
   "metadata": {},
   "source": [
    "Now we'll count the number of times each ngram occurs.  **The `cleanitem` line exists for a specific reason, try and figure out why it occurs and what's it doing.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f879ae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = {}\n",
    "for item in sorted(list(ng)):\n",
    "    cleanitem = re.sub(\",|\\'|\\(|\\)\",\"\",str(item))\n",
    "    counts.update({cleanitem:ng.count(item)})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "560fb037",
   "metadata": {},
   "source": [
    "Now you'll turn those counts into a Pandas Dataframe.  This is tricky for silly reasons, but **examine the code below to figure out how I'm doing it.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b9c861f",
   "metadata": {},
   "outputs": [],
   "source": [
    "cdf = pd.DataFrame.from_dict(counts, orient ='index')\n",
    "cdf.reset_index(inplace=True)\n",
    "cdf = cdf.rename(columns = {'index':'word', 0:'count'})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91eecc4e",
   "metadata": {},
   "source": [
    "Now **sort the dataframe in descending order, and view the top 20 rows**.  Hint: `dataframe.sort_values('col',ascending=True/False)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb86c028",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c41becc2",
   "metadata": {},
   "source": [
    "As expected, many of the most frequent words are *function words*.  **How far down the list do you need to go to start finding content words, which tell us about actual patterns in the dataset (e.g. important characters or concepts)?  Do you see any names or words which tell you about the story?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12598e1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your answer here."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6da6b66",
   "metadata": {},
   "source": [
    "You'll need to **rerun the n-gram analysis to get unigram counts so we can look at individual words**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d62b40e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Your unigram code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb657175",
   "metadata": {},
   "source": [
    "Now, create a barplot showing the counts of the 200 most frequent **single words**.  **Does this follow the expected (Zipfian) distributions?** (Hint: `plt.xticks(rotation=90);` might be useful in looking at the most frequent words in a plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8283e054",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88fb6ebf",
   "metadata": {},
   "source": [
    "Now, **create a new column in your count dataframe with the log (using `np.log`) of `count`, and graph the log counts of the most frequent words.**  Does the shape change?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "17ede352",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1f48033",
   "metadata": {},
   "source": [
    "Now, **write a for loop to do the get ngram counts for 1, 2, 3, 4, and 5 grams, and store the highest frequency gram (word/count pair) for each N.**  Do we see the highest frequency count fall off as we might expect?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3d528102",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4df2c6f2",
   "metadata": {},
   "source": [
    "### Getting into the Weed with Data\n",
    "\n",
    "Will is allergic to Cannabis, a situation which is not actually particularly uncommon (and although present from birth in Will's case, occasionally develops later in life among smokers and workers in the cannabis industry who are constantly exposed to the plants and pollen).  But as a result, Cannabis plants or smoke, alongside other allergic symptoms, make his larynx (voicebox) swell up, and potentially, shut. This is pretty unfortunate for people who enjoy breathing, and serves as a plea to ask your friends to refrain from smoking or growing around other people and focus on more considerate methods of cannabis use, but it also contextualizes why this analysis is interesting.\n",
    "\n",
    "In 2013, when he was in the depths of dissertating, Will received a Christmas gift card from his girlfriend (now wife) to a relaxation spa called 'The Wellness Center'.  Although it was a very thoughtful gift, Will immediately thought it was a joke, because, not knowing the facility, it sounded entirely like a Marijuana dispensary.  It wound up with a laugh, but everybody present agreed that it sounded like a dispensary, particularly given that Cannabis had been initially legalized under medical pretext in Colorado.\n",
    "\n",
    "An initial corpus search (documented [here](https://wstyler.ucsd.edu/posts/dispensary_names.html)) revealed that, indeed, this was a good assumption, with 'wellness' being the most common word in Dispensary names in 2013 by far.  Now, nearly 10 years later, and with recreational use now being legal without 'medical' pretext, let's see whether California cannabis retailer culture follows the same pattern, and whether 'wellness' is still a common term used in cannabis company names.\n",
    "\n",
    "`texts/ca_mj.csv` is a file containing a list of all Cannabis License Holder business, downloaded via <https://search.cannabis.ca.gov/> .  **Load in the dataset for our use in Pandas, and look at the first few rows to get a sense of the data.**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8c4856b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42b22ee3",
   "metadata": {},
   "source": [
    "There's lots of interesting data here, particularly for the GIS inclined.  **How many licenses have been issued, according to this list?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22371d1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e31b464",
   "metadata": {},
   "source": [
    "Let's focus on the `businessDbaName` and `businessLegalName` variable.  There are a huge number of 'Data not available', LLC, Inc, and such, so we should drop those too.  But we don't want to drop all rows, as many businesses have the same 'DBA' (doing business as) name as their legal name.  So, we'll just remove those strings.  **Read the code below and explain to your neighbor what it does and why.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f3746de",
   "metadata": {},
   "outputs": [],
   "source": [
    "mjdb['combined'] = mjdb['businessDbaName'].astype(str) + \" \" + mjdb['businessLegalName'].astype(str)\n",
    "mjdbclean = mjdb.replace(regex=r'Data Not Available|LLC|Inc.|Inc|,|\\.',value='')\n",
    "dispnames = list(mjdbclean['combined'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "774c2a7f",
   "metadata": {},
   "source": [
    "Let's sanity check the data and **make sure our `dispnames` list has the same number of rows as the original dataframe.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ee8cd11",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8ffc60d",
   "metadata": {},
   "source": [
    "Now, we're going to create a single chunk of text out of all of the text. **Read the code below and explain to your neighbor what it does and why**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15e6844c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dn = ' '.join([str(i).lower() for i in dispnames])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c7b497b",
   "metadata": {},
   "source": [
    "Now, you've got a bunch of text.  **Use the code from above to tokenize, create bigrams, and get counts saved as `cdf`.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0549bf2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a85f1ff4",
   "metadata": {},
   "source": [
    "Now look at the top 60 items.  **Do you see a theme in modern California Cannabis business naming?  Is it wellness?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f6eac61",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c05cd500",
   "metadata": {},
   "source": [
    "Now, find all rows which contain 'wellness' Hint: dataframe[dataframe['colname'].str.contains(\"string\")].  **Does 'Wellness center' appear?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57a0abf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d826abd",
   "metadata": {},
   "source": [
    "Bigrams, when there are many variants, can sometimes disguise or downplay particular unigrams.  **Now run a unigram model, and see where 'wellness' ranks.**  (Note: dataframe.reset_index() allows you to re-index the data after sorting the data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5343af30",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Your code here"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
